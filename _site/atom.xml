<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>BForever</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2018-08-09T16:05:59+08:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>FanHongchang</name>
   <email>11fhc@163.com</email>
 </author>

 
 <entry>
   <title>无法下载golang.org X Net解决方法</title>
   <link href="http://localhost:4000/2018/08/09/%E6%97%A0%E6%B3%95%E4%B8%8B%E8%BD%BDgolang.org-x-net%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
   <updated>2018-08-09T00:00:00+08:00</updated>
   <id>http://localhost:4000/2018/08/09/无法下载golang.org-x-net解决方法</id>
   <content type="html">&lt;h1 id=&quot;无法下载golangorgxnet解决方法&quot;&gt;无法下载golang.org/x/net解决方法&lt;/h1&gt;
&lt;p&gt;由于go的很多包都依赖了google官方的包，而google官方的包都在google服务器上，因为某些原因无法直接访问，在搜索了很多解决方案后，找到了最简单的一个方法：&lt;/p&gt;

&lt;h3 id=&quot;1-找到对应包在github的地址&quot;&gt;1. 找到对应包在github的地址&lt;/h3&gt;
&lt;h3 id=&quot;2-go-get这个地址的包&quot;&gt;2. go get这个地址的包&lt;/h3&gt;
&lt;h3 id=&quot;3-在本地创建包的原地址的文件夹&quot;&gt;3. 在本地创建包的原地址的文件夹&lt;/h3&gt;
&lt;h3 id=&quot;4-将githubcom文件夹中的这个包转移的原地址文件夹中&quot;&gt;4. 将github.com文件夹中的这个包转移的原地址文件夹中&lt;/h3&gt;

&lt;p&gt;具体到标题上的问题，我们需要首先获得该包在github上的地址&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;github.com/golang/net&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;因此，使用命令：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;go get github.com/golang/net
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;获得这个包，随后在&lt;code class=&quot;highlighter-rouge&quot;&gt;$GOPATH/src&lt;/code&gt;中创建&lt;code class=&quot;highlighter-rouge&quot;&gt;golang.org/x/&lt;/code&gt;文件夹，并将&lt;code class=&quot;highlighter-rouge&quot;&gt;github.com/golang/net&lt;/code&gt;剪切到其中，这样我们就可以&lt;code class=&quot;highlighter-rouge&quot;&gt;import &quot;golang.org/x/net&quot;&lt;/code&gt;了&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Ifb上挂载netem</title>
   <link href="http://localhost:4000/2018/08/03/IFB%E4%B8%8A%E6%8C%82%E8%BD%BDNETEM/"/>
   <updated>2018-08-03T00:00:00+08:00</updated>
   <id>http://localhost:4000/2018/08/03/IFB上挂载NETEM</id>
   <content type="html">&lt;h1 id=&quot;ifb上挂载netem&quot;&gt;IFB上挂载NETEM&lt;/h1&gt;
&lt;h2 id=&quot;转发虚拟网卡的ingress&quot;&gt;转发虚拟网卡的ingress&lt;/h2&gt;
&lt;h3 id=&quot;建立虚拟网卡的ingress转发到ifb0每一个pod&quot;&gt;建立虚拟网卡的ingress转发到ifb0（每一个Pod）：&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc qdisc add dev calixxxxxxxxxxx ingress
tc filter add dev calixxxxxxxxxxx parent ffff: protocol ip prio 10 u32 match u32 0 0 flowid 1:1 action mirred egress redirect dev ifb0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;建立ifb0的根队列htb每一个node&quot;&gt;建立ifb0的根队列htb（每一个Node）：&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc qdisc add dev ifb0 root handle 1: htb default 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;为x号pod建立一个类1x每一个pod&quot;&gt;为x号Pod建立一个类1:x（每一个Pod）：&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc class add dev ifb0 parent 1: classid 1:x htb rate 100mbps
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;为podx的ipxxxx建立一个过滤器使来自该podx的流量进入子类1x每一个pod&quot;&gt;为Podx的IPx.x.x.x建立一个过滤器，使来自该Podx的流量进入子类1:x（每一个Pod）：&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc filter add dev ifb0 protocol ip parent 1:0 prio 1 u32 match ip src x.x.x.x flowid 1:x
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;为每一个类建立一个netem队列x11每一个pod&quot;&gt;为每一个类建立一个netem队列x+1:1（每一个Pod）&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc qdisc add dev ifb0 parent 1:1 handle x+1: netem delay 100ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;转发虚拟网卡的egress&quot;&gt;转发虚拟网卡的egress&lt;/h2&gt;
&lt;h3 id=&quot;为虚拟网卡的egress建立htb队列1每一个pod&quot;&gt;为虚拟网卡的egress建立HTB队列1:（每一个Pod）&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc qdisc add dev calixxxxxxxxxxx root handle 1: htb default 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;为htb建立子类11每一个pod&quot;&gt;为HTB建立子类1:1（每一个Pod）&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc class add dev calix parent 1: classid 1:1 htb rate 100mbps
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;为子类建立队列每一个pod&quot;&gt;为子类建立队列（每一个Pod）&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc qdisc add dev calix parent 1:1 pfifo limit 1600
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;转发到ifb1每一个pod&quot;&gt;转发到IFB1（每一个Pod）&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc filter add dev calix parent 1: proto ip prio 1 u32 match u32 0 0 flowid 1:1 action mirred egress redirect dev ifb1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;建立ifb1的根队列htb每一个node&quot;&gt;建立ifb1的根队列htb（每一个Node）：&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc qdisc add dev ifb1 root handle 1: htb default 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;为x号pod建立一个类1x每一个pod-1&quot;&gt;为x号Pod建立一个类1:x（每一个Pod）：&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc class add dev ifb1 parent 1: classid 1:x htb rate 100mbps
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;为podx的ipxxxx建立一个过滤器使来自该podx的流量进入子类1x每一个pod-1&quot;&gt;为Podx的IPx.x.x.x建立一个过滤器，使来自该Podx的流量进入子类1:x（每一个Pod）：&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc filter add dev ifb1 protocol ip parent 1:0 prio 1 u32 match ip src x.x.x.x flowid 1:x
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;为每一个类建立一个netem队列x11每一个pod-1&quot;&gt;为每一个类建立一个netem队列x+1:1（每一个Pod）&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc qdisc add dev ifb1 parent 1:1 handle x+1: netem delay 100ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Ifb</title>
   <link href="http://localhost:4000/2018/08/02/IFB/"/>
   <updated>2018-08-02T00:00:00+08:00</updated>
   <id>http://localhost:4000/2018/08/02/IFB</id>
   <content type="html">&lt;h1 id=&quot;ifb&quot;&gt;IFB&lt;/h1&gt;
&lt;p&gt;IFB（中介功能块设备）是IMQ（中介队列设备）的继任者，IMQ从来没有被集成过，IFB拥有IMQ的优点，在SMP上更加清晰明了，并且代码量缩减了非常多，旧的中介设备功能仍然保留，但在你使用actions时你需要新的&lt;/p&gt;

&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;IFB使用场景&lt;/li&gt;
  &lt;li&gt;典型应用&lt;/li&gt;
  &lt;li&gt;跑一个小测试&lt;/li&gt;
  &lt;li&gt;IFB样例&lt;/li&gt;
  &lt;li&gt;IFB的依赖&lt;/li&gt;
  &lt;li&gt;IFB样例&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ifb使用场景&quot;&gt;IFB使用场景&lt;/h2&gt;
&lt;p&gt;据我所知，如下场景是人们使用IMQ的理由：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;队列/策略是针对单个网卡而不是应用到整个系统的，而IMQ允许多个设备共享队列/策略&lt;/li&gt;
  &lt;li&gt;允许入境流量被整流而不仅仅是被丢弃。我不知道有什么研究能说明丢包比整流更差，如果有我会十分感兴趣。&lt;/li&gt;
  &lt;li&gt;思科的&lt;a href=&quot;http://www.cisco.com/c/en/us/support/docs/quality-of-service-qos/qos-policing/19645-policevsshape.html#selectioncriteria&quot;&gt;Comparing Traffic Policing and Traffic Shaping for Bandwidth Limiting&lt;/a&gt;表明整流（排队）比策略（限流）更好，因为策略会丢弃多余的包，限制TCP的窗口大小并且减少基于TCP的流的输出速率&lt;/li&gt;
  &lt;li&gt;现实中几乎&lt;a href=&quot;http://www.caida.org/data/realtime/passive/?monitor=equinix-chicago-dirA&quot;&gt;所有的互联网&lt;/a&gt;流量都是基于TCP的&lt;/li&gt;
  &lt;li&gt;非常有意思的应用：如果你在提供P2P服务，你可能会想要优先处理本地流量而不是其他使用你的系统上/下载的流量。所以基于状态的QoS是一种解决方案，人们用在本地流量入口之前挂载IMQ的方式实现了它。我认为这是Linux上非常有特点的应用（不仅仅是IMQ）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不过我不会再使用netfilter hooks的方式实现这个，我也不会认为这值的我修改IFB获取三层网络的信息来实现它&lt;/p&gt;

&lt;p&gt;替代的方案是使用一个跟踪连接的action。这个action会选择性的在入境数据包上查询/创建连接跟踪状态。数据包因此可以根据发生了什么来被重定向到IFB。如果我们发现它们是已知的状态我们就可以把它发送到不同于还没有状态的数据包的队列里。这取决于管理员制定的规则。&lt;/p&gt;

&lt;p&gt;现在这个功能还不存在，我决定不在补丁上release它，如果有强烈要求我会增加这个特性&lt;/p&gt;

&lt;p&gt;你现在可以用IFB做的是actions&lt;/p&gt;

&lt;p&gt;假设你在来自192.168.200.200/32上的数据包上限流到100kbps&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc filter add dev eth0 parent 1: protocol ip prio 10 u32 \
 match ip src 192.168.200.200/32 flowid 1:2 \
 action police rate 100kbit burst 90k drop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果你在eth0上运行tcpdump，你会看到所有来自于192.168.200.200/32的数据包是否被丢弃。扩展这条规则来只观察这些包：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tc filter add dev eth0 parent 1: protocol ip prio 10 u32 \
 match ip src 192.168.200.200/32 flowid 1:2 \
 action police rate 10kbit burst 90k drop \
 action mirred egress mirror dev ifb0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;现在在ifb0上开启tcpdump就可以只观察这些包：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tcpdump -n -i ifb0 -x -e -t
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这是一个非常好的debug和log的接口&lt;/p&gt;

&lt;p&gt;如果你用重定向代替镜像，这些包会进入黑洞再也无法出来，这个重定向的行为会在新的补丁上被修改（但是镜像没有问题）&lt;/p&gt;

&lt;h2 id=&quot;典型应用&quot;&gt;典型应用&lt;/h2&gt;
&lt;p&gt;你可以使用新的补丁来实现以前用IMQ实现的功能&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export TC=&quot;/sbin/tc&quot;
$TC qdisc add dev ifb0 root handle 1: prio 
$TC qdisc add dev ifb0 parent 1:1 handle 10: sfq
$TC qdisc add dev ifb0 parent 1:2 handle 20: tbf rate 20kbit buffer 1600 limit 3000
$TC qdisc add dev ifb0 parent 1:3 handle 30: sfq                                
$TC filter add dev ifb0 protocol ip pref 1 parent 1: handle 1 fw classid 1:1
$TC filter add dev ifb0 protocol ip pref 2 parent 1: handle 2 fw classid 1:2
ifconfig ifb0 up
$TC qdisc add dev eth0 ingress
# redirect all IP packets arriving in eth0 to ifb0 
# use mark 1 --&amp;gt; puts them onto class 1:1
$TC filter add dev eth0 parent ffff: protocol ip prio 10 u32 \
  match u32 0 0 flowid 1:1 \
  action ipt -j MARK --set-mark 1 \
  action mirred egress redirect dev ifb0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;跑一个小测试&quot;&gt;跑一个小测试&lt;/h2&gt;
&lt;p&gt;从另一台机器ping过来，这样你可以获得入境流量：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@jzny action-tests]# ping 10.22
PING 10.22 (10.0.0.22): 56 data bytes
64 bytes from 10.0.0.22: icmp_seq=0 ttl=64 time=2.8 ms
64 bytes from 10.0.0.22: icmp_seq=1 ttl=64 time=0.6 ms
64 bytes from 10.0.0.22: icmp_seq=2 ttl=64 time=0.6 ms
--- 10.22 ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 0.6/1.3/2.8 ms
[root@jzny action-tests]#
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;现在看一下stats：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[root@jmandrake]:~# $TC -s filter show parent ffff: dev eth0
filter protocol ip pref 10 u32 
filter protocol ip pref 10 u32 fh 800: ht divisor 1 
filter protocol ip pref 10 u32 fh 800::800 order 2048 key ht 800 bkt 0 flowid 1:1 
  match 00000000/00000000 at 0
        action order 1: tablename: mangle  hook: NF_IP_PRE_ROUTING 
        target MARK set 0x1  
        index 1 ref 1 bind 1 installed 4195sec  used 27sec 
         Sent 252 bytes 3 pkts (dropped 0, overlimits 0) 
        action order 2: mirred (Egress Redirect to device ifb0) stolen
        index 1 ref 1 bind 1 installed 165 sec used 27 sec
         Sent 252 bytes 3 pkts (dropped 0, overlimits 0) 
[root@jmandrake]:~# $TC -s qdisc
qdisc sfq 30: dev ifb0 limit 128p quantum 1514b 
 Sent 0 bytes 0 pkts (dropped 0, overlimits 0) 
qdisc tbf 20: dev ifb0 rate 20Kbit burst 1575b lat 2147.5s 
 Sent 210 bytes 3 pkts (dropped 0, overlimits 0) 
qdisc sfq 10: dev ifb0 limit 128p quantum 1514b 
 Sent 294 bytes 3 pkts (dropped 0, overlimits 0) 
qdisc prio 1: dev ifb0 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1
 Sent 504 bytes 6 pkts (dropped 0, overlimits 0) 
qdisc ingress ffff: dev eth0 ---------------- 
 Sent 308 bytes 5 pkts (dropped 0, overlimits 0) 
[root@jmandrake]:~# ifconfig ifb0
ifb0    Link encap:Ethernet  HWaddr 00:00:00:00:00:00  
          inet6 addr: fe80::200:ff:fe00:0/64 Scope:Link
           UP BROADCAST RUNNING NOARP  MTU:1500  Metric:1
           RX packets:6 errors:0 dropped:3 overruns:0 frame:0
           TX packets:3 errors:0 dropped:0 overruns:0 carrier:0
           collisions:0 txqueuelen:32 
           RX bytes:504 (504.0 b)  TX bytes:252 (252.0 b)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;伪设备（指IFB）仍然表现得像以前一样&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>创建一个包含tc的alpine镜像</title>
   <link href="http://localhost:4000/2018/07/24/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%8C%85%E5%90%ABTC%E7%9A%84Alpine%E9%95%9C%E5%83%8F/"/>
   <updated>2018-07-24T00:00:00+08:00</updated>
   <id>http://localhost:4000/2018/07/24/创建一个包含TC的Alpine镜像</id>
   <content type="html">&lt;h1 id=&quot;创建一个包含tc的alpine镜像&quot;&gt;创建一个包含TC的Alpine镜像&lt;/h1&gt;

&lt;h2 id=&quot;镜像的创建&quot;&gt;镜像的创建&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;更换镜像至ustc（为了测试时的速度）&lt;/li&gt;
  &lt;li&gt;安装musl-dev make gcc linux-headers bison flex以使TC可以编译&lt;/li&gt;
  &lt;li&gt;拷贝进TC的源代码&lt;/li&gt;
  &lt;li&gt;进入源代码文件夹进行编译&lt;/li&gt;
  &lt;li&gt;运行top（或任何不自动退出的程序）以便exec进入容器&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Dockerfile如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM alpine

RUN rm /etc/apk/repositories
RUN echo -e &quot;http://mirrors.ustc.edu.cn/alpine/v3.8/main\nhttp://mirrors.ustc.edu.cn/alpine/v3.8/community&quot; &amp;gt; /etc/apk/repositories

RUN set -ex \
        &amp;amp;&amp;amp; apk update &amp;amp;&amp;amp; apk add --no-cache --virtual .build-deps \
                musl-dev \
                make \
                gcc \
                linux-headers \
                bison \
                flex

ADD iproute /code/iproute
RUN cd code/iproute &amp;amp;&amp;amp; make
CMD top
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;部署用yaml的设置&quot;&gt;部署用yaml的设置&lt;/h2&gt;

&lt;h3 id=&quot;tc内核通信权限设置&quot;&gt;TC内核通信权限设置&lt;/h3&gt;
&lt;p&gt;由于TC与内核通信并更改网络设置，需要提高容器权限，这需要在YAML文件中进行设置：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spec:
  containers:
    securityContext:
      privileged: true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这样容器内的TC才有权限通过netlink与内核进行通信&lt;/p&gt;

&lt;h3 id=&quot;网络设置&quot;&gt;网络设置&lt;/h3&gt;

&lt;p&gt;TC所在的POD需要能够设置该Node的所有网卡，因此需要设置为hostNetwork网络，另外需要设置DNS以使Pod能以POD的身份访问service&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    spec:
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最后的部署用的YAML如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: test-deployment
spec:
  selector:
    matchLabels:
      app: test
  replicas: 1
  template:
    metadata:
      labels:
        app: test
    spec:
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: test
        image: foo
        imagePullPolicy: Never
        securityContext:
          privileged: true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>在k8s上跑一个helloworld</title>
   <link href="http://localhost:4000/2018/07/23/%E5%9C%A8K8S%E4%B8%8A%E8%B7%91%E4%B8%80%E4%B8%AAhelloworld/"/>
   <updated>2018-07-23T00:00:00+08:00</updated>
   <id>http://localhost:4000/2018/07/23/在K8S上跑一个helloworld</id>
   <content type="html">&lt;h1 id=&quot;在k8s上跑一个helloworld&quot;&gt;在K8S上跑一个helloworld&lt;/h1&gt;
&lt;h2 id=&quot;建立docker镜像&quot;&gt;建立docker镜像&lt;/h2&gt;
&lt;p&gt;为了方便起见，这里直接使用一个js网页作为应用，以此创建镜像&lt;/p&gt;
&lt;h3 id=&quot;hello-world网页&quot;&gt;hello world网页&lt;/h3&gt;
&lt;p&gt;创建server.js，输入以下代码创建helloworld网页：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;var http = require('http');

var handleRequest = function(request, response) {
  console.log('Received request for URL: ' + request.url);
  response.writeHead(200);
  response.end('Hello World!');
};
var www = http.createServer(handleRequest);
www.listen(8080);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;dockerfile&quot;&gt;Dockerfile&lt;/h3&gt;
&lt;p&gt;创建Dockerfile文件，配置镜像：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM node:6.9.2
EXPOSE 8080
COPY server.js .
CMD node server.js
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;其中，FROM是从官方镜像库取得node的镜像，EXPOSE表示暴露本容器的8080端口，COPY将server.js加入容器，CMD为容器中执行的命令&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;更详细的Dockerfile写法见官方文档&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;创建镜像&quot;&gt;创建镜像&lt;/h3&gt;
&lt;p&gt;配置好Dockerfile后，就可以使用docker的build命令根据Dockerfile的内容创建一个镜像：
&lt;code class=&quot;highlighter-rouge&quot;&gt;docker build -t hello-node:v1 .&lt;/code&gt;
这里注意不要遗漏最后的&lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;在kubernetes上以该镜像创建一个pod&quot;&gt;在Kubernetes上以该镜像创建一个POD&lt;/h2&gt;
&lt;p&gt;在K8S集群配置完毕后，执行&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl run hello-node --image=hello-node:v1 --port=8080 --image-pull-policy=Never&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;即可在K8S上建立一个新的运行刚刚建立的镜像的POD&lt;/p&gt;

&lt;p&gt;但是此时由于POD默认不暴露在外部，因此我们无法观察到node的输出，为此需要创建一个service将该POD的端口暴露出来&lt;/p&gt;

&lt;h2 id=&quot;访问该pod&quot;&gt;访问该POD&lt;/h2&gt;
&lt;h3 id=&quot;kubernetes-service&quot;&gt;Kubernetes Service&lt;/h3&gt;
&lt;p&gt;Service有几个种类，默认的是cluster-ip，即只能通过pod在集群内部的IP地址进行对service的访问&lt;/p&gt;

&lt;p&gt;第二种是nodeport，即在每一个Node上暴露出一个端口：nodePort，外部网络可以通过（任一Node）[NodeIP]:[NodePort]访问到后端的Service。&lt;/p&gt;

&lt;p&gt;第三种是loadbalancer，请求底层云平台创建一个负载均衡器，将每个Node作为后端，进行服务分发。该模式需要底层云平台（例如GCE）支持&lt;/p&gt;

&lt;p&gt;最简单的就是直接开启一个默认的clusterip的service，在master上直接通过集群内部IP访问helloworld：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl expose deployment hello-node --port=8080 --target-port=8080&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;其他方式比如NodePort可以通过&lt;code class=&quot;highlighter-rouge&quot;&gt;--type=NodePort&lt;/code&gt;参数指定&lt;/p&gt;

&lt;h3 id=&quot;进行访问&quot;&gt;进行访问&lt;/h3&gt;
&lt;p&gt;在创建好service之后，就可以使用&lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl get service&lt;/code&gt;查看当前运行的service，其中可以看到hello-node的ClusterIP，在浏览器中访问该IP：8080即可看到hello world！&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>在centos7上搭建k8s</title>
   <link href="http://localhost:4000/2018/07/20/%E5%9C%A8CentOS7%E4%B8%8A%E6%90%AD%E5%BB%BAK8S/"/>
   <updated>2018-07-20T00:00:00+08:00</updated>
   <id>http://localhost:4000/2018/07/20/在CentOS7上搭建K8S</id>
   <content type="html">&lt;h1 id=&quot;在centos7上搭建k8s&quot;&gt;在CentOS7上搭建K8S&lt;/h1&gt;
&lt;h2 id=&quot;来源&quot;&gt;来源&lt;/h2&gt;
&lt;p&gt;中文教程 &lt;a href=&quot;http://blog.51cto.com/devingeng/2096495?from=singlemessage&quot;&gt;http://blog.51cto.com/devingeng/2096495?from=singlemessage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;官方文档 &lt;a href=&quot;https://kubernetes.io/docs/setup/independent/install-kubeadm/&quot;&gt;https://kubernetes.io/docs/setup/independent/install-kubeadm/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;准备&quot;&gt;准备&lt;/h2&gt;
&lt;h3 id=&quot;1-centos-7&quot;&gt;1 centOS 7&lt;/h3&gt;
&lt;h3 id=&quot;2-以root登陆建议&quot;&gt;2 以root登陆（建议）&lt;/h3&gt;
&lt;h3 id=&quot;3-关闭防火墙&quot;&gt;3 关闭防火墙&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;关闭firewall，iptables：
&lt;code class=&quot;highlighter-rouge&quot;&gt;systemctl stop firewalld.service&lt;/code&gt; #停止firewall
&lt;code class=&quot;highlighter-rouge&quot;&gt;systemctl disable firewalld.service&lt;/code&gt; #禁止firewall开机启动&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;firewall-cmd --state&lt;/code&gt; #查看默认防火墙状态（关闭后显示not running，开启后显示running）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;4-关闭selinux&quot;&gt;4 关闭SElinux&lt;/h3&gt;
&lt;p&gt;暂时关闭：
&lt;code class=&quot;highlighter-rouge&quot;&gt;setenforce 0&lt;/code&gt;
永久关闭：
&lt;code class=&quot;highlighter-rouge&quot;&gt;vim /etc/selinux/config&lt;/code&gt;打开selinux配置文件&lt;/p&gt;

&lt;p&gt;找到SELINUX=参数&lt;/p&gt;

&lt;p&gt;参数可选（enforcing、permissive、disabled）&lt;/p&gt;

&lt;p&gt;disabled即为关闭SElinux&lt;/p&gt;

&lt;h3 id=&quot;5-关闭swap&quot;&gt;5 关闭swap&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;swapoff -a&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;6-配置系统内核参数使流过网桥的流量也进入iptablesnetfilter框架中开启ipv4的forwarding&quot;&gt;6 配置系统内核参数使流过网桥的流量也进入iptables/netfilter框架中，开启ipv4的forwarding&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;在/etc/sysctl.conf中添加以下配置：&lt;/p&gt;

  &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; net.bridge.bridge-nf-call-iptables = 1
 net.bridge.bridge-nf-call-ip6tables = 1 
 net.ipv4.ip_forward=1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
  &lt;p&gt;并执行&lt;code class=&quot;highlighter-rouge&quot;&gt;sysctl -p&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;7-配置阿里云镜像&quot;&gt;7 配置阿里云镜像&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
EOF
yum -y install epel-release
yum clean all
yum makecache
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;安装相关工具&quot;&gt;安装相关工具&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;以下内容于51CTO博客作者Devin的原创作品整理而来，如需转载，请注明出处&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;1-安装docker以及kubeadm相关工具&quot;&gt;1 安装docker以及kubeadm相关工具&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;yum -y install docker kubelet kubeadm kubectl&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-启动docker以及kubeadm服务&quot;&gt;2 启动docker以及kubeadm服务&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;systemctl enable docker &amp;amp;&amp;amp; systemctl start docker
systemctl enable kubelet &amp;amp;&amp;amp; systemctl start kubelet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-下载k8s相关镜像&quot;&gt;3 下载K8S相关镜像&lt;/h3&gt;
&lt;p&gt;因为无法直接访问gcr.io下载镜像，所以需要配置一个国内的容器镜像加速器:&lt;/p&gt;

&lt;p&gt;登录 https://cr.console.aliyun.com/&lt;/p&gt;

&lt;p&gt;在页面中找到并点击镜像加速按钮，即可看到属于自己的专属加速链接，选择Centos版本后即可看到配置方法。&lt;/p&gt;

&lt;p&gt;解决完加速器的问题之后，开始下载k8s相关镜像，下载后将镜像名改为k8s.gcr.io/开头的名字，以便kubeadm识别使用:(注意将版本号替换为当前安装的版本）&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;kube-proxy-amd64:v1.11.0 kube-scheduler-amd64:v1.11.0 kube-controller-manager-amd64:v1.11.0 kube-apiserver-amd64:v1.11.0
etcd-amd64:3.2.18 pause-amd64:3.1 kubernetes-dashboard-amd64:v1.8.3 k8s-dns-sidecar-amd64:1.14.8 k8s-dns-kube-dns-amd64:1.14.8
k8s-dns-dnsmasq-nanny-amd64:1.14.8 coredns:1.1.3&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;imageName &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[@]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do
  &lt;/span&gt;docker pull keveon/&lt;span class=&quot;nv&quot;&gt;$imageName&lt;/span&gt;
  docker tag keveon/&lt;span class=&quot;nv&quot;&gt;$imageName&lt;/span&gt; k8s.gcr.io/&lt;span class=&quot;nv&quot;&gt;$imageName&lt;/span&gt;
  docker rmi keveon/&lt;span class=&quot;nv&quot;&gt;$imageName&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;4-初始化安装k8s-master&quot;&gt;4 初始化安装K8S Master&lt;/h3&gt;
&lt;p&gt;下载完成后，执行kubeadm init:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kubeadm init --kubernetes-version=v1.11.0 --pod-network-cidr=192.168.0.0/16&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;执行过程中可能会出现版本问题，此时自行按照版本提示使用&lt;code class=&quot;highlighter-rouge&quot;&gt;docker pull ...&lt;/code&gt;获得相应镜像并改名即可&lt;/p&gt;

&lt;p&gt;上面的命令大约需要1分钟的过程，期间可以观察下tail -f /var/log/message日志文件的输出，掌握该配置过程和进度。上面最后一段的输出信息保存一份，后续添加工作节点还要用到。&lt;/p&gt;

&lt;p&gt;类似于&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubeadm join 10.211.55.10:6443 --token 1xuwcb.oijnat5tkla6r384 --discovery-token-ca-cert-hash sha256:bcbf083a3fab2422ae0615b421d71a2275f2a974746989e59672a100a071ba30
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;5配置kubectl认证信息master节点操作&quot;&gt;5.配置kubectl认证信息（Master节点操作）&lt;/h3&gt;

&lt;p&gt;对于非root用户&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;对于root用户&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export KUBECONFIG=/etc/kubernetes/admin.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;也可以直接放到~/.bash_profile&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &amp;gt;&amp;gt; ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;6安装网络组件&quot;&gt;6.安装网络组件&lt;/h3&gt;

&lt;p&gt;这里我们使用Calico：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl apply -f \
https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/kubeadm/1.7/calico.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;然后使用&lt;code class=&quot;highlighter-rouge&quot;&gt;watch kubectl get pods --all-namespaces&lt;/code&gt;检查coreDNS运行状态，如果为running则可以继续&lt;/p&gt;

&lt;h3 id=&quot;7在本机运行pods&quot;&gt;7.在本机运行pods&lt;/h3&gt;
&lt;p&gt;执行
&lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl taint nodes --all node-role.kubernetes.io/master-&lt;/code&gt;
允许master上调度pods&lt;/p&gt;

&lt;h2 id=&quot;搭建新的node并join进集群&quot;&gt;搭建新的NODE并join进集群&lt;/h2&gt;
&lt;h3 id=&quot;准备-1&quot;&gt;准备&lt;/h3&gt;
&lt;p&gt;首先安装新的虚拟机并安装CentOS，然后按照本文第一部分安装kubeadm和docker等组件&lt;/p&gt;

&lt;h3 id=&quot;join&quot;&gt;join&lt;/h3&gt;
&lt;p&gt;将master init后输出的提示在新机器上执行
&lt;code class=&quot;highlighter-rouge&quot;&gt;kubeadm join 10.211.55.10:6443 --token 1xuwcb.oijnat5tkla6r384 --discovery-token-ca-cert-hash sha256:bcbf083a3fab2422ae0615b421d71a2275f2a974746989e59672a100a071ba30&lt;/code&gt;
即可加入集群&lt;/p&gt;

&lt;h3 id=&quot;默认token的有效期为24小时当过期之后该token就不可用了解决方法如下&quot;&gt;默认token的有效期为24小时，当过期之后，该token就不可用了。解决方法如下：&lt;/h3&gt;

&lt;p&gt;重新生成新的token&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kubeadm token create&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;kubeadm token list&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;获取ca证书sha256编码hash值
&lt;code class=&quot;highlighter-rouge&quot;&gt;openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&amp;gt;/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;节点加入集群
&lt;code class=&quot;highlighter-rouge&quot;&gt;kubeadm join --token aa78f6.8b4cafc8ed26c34f --discovery-token-ca-cert-hash sha256:...&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;关闭node&quot;&gt;关闭node&lt;/h3&gt;
&lt;p&gt;在master执行&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl drain &amp;lt;node name&amp;gt; --delete-local-data --force --ignore-daemonsets
kubectl delete node &amp;lt;node name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;在该node执行
&lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl reset&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;即可关闭该node&lt;/p&gt;
</content>
 </entry>
 

</feed>
